apiVersion: 1

groups:
  - orgId: 1
    name: Loki Critical Alerts
    folder: Loki Alerts
    interval: 1m
    rules:
      - uid: loki-ingestion-stopped
        title: Loki Ingestion Stopped
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: sum(count_over_time({job=~".+"}[5m]))
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 0
                    type: eq
        noDataState: Alerting
        execErrState: Alerting
        for: 5m
        annotations:
          summary: No logs received from any service in the last 5 minutes
          description: Loki is not receiving any log data. Check Promtail agents and Loki service.
        labels:
          severity: critical

      - uid: vaultwarden-auth-failures
        title: Vaultwarden Authentication Failures
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: sum(count_over_time({job="vaultwarden"} |~ "(?i)(failed|invalid|unauthorized)" [5m]))
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 5
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 0s
        annotations:
          summary: Multiple Vaultwarden authentication failures detected
          description: More than 5 failed auth attempts in the last 5 minutes. Possible brute force attack.
        labels:
          severity: critical

      - uid: pbs-backup-failure
        title: PBS Backup Failure
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 600
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: count_over_time({job="pbs"} |~ "TASK ERROR" [10m])
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 0
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 0s
        annotations:
          summary: Proxmox Backup Server reported a task error
          description: PBS backup job has failed. Check PBS logs for details.
        labels:
          severity: critical

      - uid: critical-system-error
        title: Critical System Error
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: sum(count_over_time({job=~".+"} |~ "(?i)(fatal|panic)" [5m]))
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 0
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 0s
        annotations:
          summary: Critical system error detected
          description: A fatal or panic error was logged. Immediate attention required.
        labels:
          severity: critical

  - orgId: 1
    name: Loki Warning Alerts
    folder: Loki Alerts
    interval: 1m
    rules:
      - uid: high-error-rate
        title: High Error Rate
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: sum(count_over_time({job=~"pbs|vaultwarden|zigbee2mqtt|node-red|mosquitto|influxdb|grafana"} |~ "(?i)error" [5m]))
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 100
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: High error rate across services
          description: More than 100 errors logged in the last 5 minutes across core services.
        labels:
          severity: warning

      - uid: zigbee-device-offline
        title: Zigbee Device Offline
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: count_over_time({job="zigbee2mqtt"} |~ "(?i)(offline|unavailable)" [5m])
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 0
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 5m
        annotations:
          summary: Zigbee device went offline
          description: A Zigbee device has gone offline or become unavailable.
        labels:
          severity: warning

      - uid: traefik-5xx-errors
        title: Traefik 5xx Errors
        condition: C
        data:
          - refId: A
            relativeTimeRange:
              from: 300
              to: 0
            datasourceUid: P8E80F9AEF21F6940
            model:
              expr: sum(count_over_time({job="traefik"} |~ "\" 5[0-9]{2} " [5m]))
              refId: A
          - refId: B
            datasourceUid: __expr__
            model:
              refId: B
              type: reduce
              expression: A
              reducer: last
          - refId: C
            datasourceUid: __expr__
            model:
              refId: C
              type: threshold
              expression: B
              conditions:
                - evaluator:
                    params:
                      - 10
                    type: gt
        noDataState: OK
        execErrState: Alerting
        for: 2m
        annotations:
          summary: Traefik returning server errors
          description: More than 10 HTTP 5xx errors in the last 5 minutes. Backend services may be unhealthy.
        labels:
          severity: warning
